{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1.Coding the Likelihood Function\n",
        "#First of all in this assignment we should implement the likelihood function for an AR(7) model in Python\n",
        "#to code both the conditional and unconditional likelihood functions."
      ],
      "metadata": {
        "id": "bYtFwHDGs5dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pzxxI3skCWti"
      },
      "outputs": [],
      "source": [
        "# Installing packages\n",
        "import pandas as pd\n",
        "from numpy.linalg import solve\n",
        "import numpy as np\n",
        "import scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing packages\n",
        "from numpy import linalg as la\n",
        "from scipy.optimize import approx_fprime\n",
        "from scipy.optimize import minimize\n",
        "from scipy.optimize import Bounds\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import multivariate_normal\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Cv1bHDS2CnbU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONDITIONAL LIKELIHOOD -Implementation in python\n",
        "#the provided code below calculates the log-likelihood of an autoregressive model with lag 7 (AR(7)) given a set of parameters (params) and observed data (y). It first calculates the unconditional mean and covariance matrix of the AR(7) process using the parameters. Then, it checks if the process is stationary; if not, it returns negative infinity as the log-likelihood.\n",
        "# If the process is stationary, it computes the conditional likelihood by assuming that the observed data follows a multivariate normal distribution with mean c plus a linear combination of lagged values (Xf @ phi) and variance sigma2. Finally, it sums the log probability density function of each observed data point given the calculated mean and variance.\n"
      ],
      "metadata": {
        "id": "WWGPk8bgEb3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lagged_matrix(Y, max_lag=7):\n",
        "    n = len(Y)\n",
        "    lagged_matrix = np.full((n, max_lag), np.nan)\n",
        "    # Fill each column with the appropriately lagged data\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        lagged_matrix[lag:, lag - 1] = Y[:-lag]\n",
        "    return lagged_matrix\n",
        "def cond_loglikelihood_ar7(params, y):\n",
        "    c = params[0]\n",
        "    phi = params[1:8]\n",
        "    sigma2 = params[8]\n",
        "    mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)\n",
        "    ## We could check that at phis the process is stationary and return -Inf if it is not\n",
        "    if not(stationary):\n",
        "        return -np.inf\n",
        "    ## The distribution of\n",
        "    # y_t|y_{t-1}, ..., y_{t-7} ~ N(c+\\phi_{1}*y_{t-1}+...+\\phi_{7}y_{t-7}, sigma2)\n",
        "    ## Create lagged matrix\n",
        "    X = lagged_matrix(y, 7)\n",
        "    yf = y[7:]\n",
        "    Xf = X[7:,:]\n",
        "    loglik = np.sum(norm.logpdf(yf, loc=(c + Xf@phi), scale=np.sqrt(sigma2)))\n",
        "    return loglik"
      ],
      "metadata": {
        "id": "xgZwy2kLGmtP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#UNCONDITIONAL LIKELIHOOD-Implementation in python\n",
        "#So the provided code below in the  unconditional_ar_mean_variance function calculates the mean vector and covariance matrix of an autoregressive (AR) process of order 7 (AR(7)), considering parameters such as the constant term (c), autoregressive coefficients (phis), and error variance (sigma2). It constructs the transition matrix A from the autoregressive coefficients, checks for the stationarity of the process, and computes the mean vector using matrix algebra. Additionally, it solves the discrete Lyapunov equation to find the covariance matrix.\n",
        "#The uncond_loglikelihood_ar7 function utilizes these statistics to compute the unconditional log-likelihood by combining the conditional log-likelihood of observed data with the probability density function of the initial observations under the AR(7) process. If the process is not stationary, it returns negative infinity as the log-likelihood."
      ],
      "metadata": {
        "id": "RNnQHTGCHQV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unconditional_ar_mean_variance(c, phis, sigma2):\n",
        "    ## The length of phis is p\n",
        "    p = len(phis)\n",
        "    A = np.zeros((p, p))\n",
        "    A[0, :] = phis\n",
        "    A[1:, 0:(p-1)] = np.eye(p-1)\n",
        "    ## Check for stationarity\n",
        "    eigA = np.linalg.eig(A)\n",
        "    if all(np.abs(eigA.eigenvalues)<1):\n",
        "        stationary = True\n",
        "    else:\n",
        "        stationary = False\n",
        "    # Create the vector b\n",
        "    b = np.zeros((p, 1))\n",
        "    b[0, 0] = c\n",
        "    # Compute the mean using matrix algebra\n",
        "    I = np.eye(p)\n",
        "    mu = np.linalg.inv(I - A) @ b\n",
        "    # Solve the discrete Lyapunov equation\n",
        "    Q = np.zeros((p, p))\n",
        "    Q[0, 0] = sigma2\n",
        "    #Sigma = np.linalg.solve(I - np.kron(A, A), Q.flatten()).reshape(7, 7)\n",
        "    Sigma = scipy.linalg.solve_discrete_lyapunov(A, Q)\n",
        "    return mu.ravel(), Sigma, stationary\n"
      ],
      "metadata": {
        "id": "_lUiL1PGIgX4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uncond_loglikelihood_ar7(params, y):\n",
        "    ## The unconditional loglikelihood\n",
        "    ## is the unconditional \"plus\" the density of the\n",
        "    ## first p (7 in our case) observations\n",
        "    cloglik = cond_loglikelihood_ar7(params, y)\n",
        "    ## Calculate initial\n",
        "    # y_1, ..., y_7 ~ N(mu, sigma_y)\n",
        "    c = params[0]\n",
        "    phi = params[1:8]\n",
        "    sigma2 = params[8]\n",
        "    mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)\n",
        "    if not(stationary):\n",
        "        return -np.inf\n",
        "    mvn = multivariate_normal(mean=mu, cov=Sigma, allow_singular=True)\n",
        "    uloglik = cloglik + mvn.logpdf(y[0:7])\n",
        "    return uloglik"
      ],
      "metadata": {
        "id": "H1GDjFISJgna"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Maximizing the Likelihood (INDPRO VARIABLE)"
      ],
      "metadata": {
        "id": "qoKTMx3WJw_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting directory to the csv file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SNG_Team = '/content/drive/My Drive/current.csv'\n",
        "\n",
        "# Loading the dataframe\n",
        "df = pd.read_csv(SNG_Team)\n",
        "df_cleaned = df.drop(index=0)\n",
        "df_cleaned.reset_index(drop=True, inplace=True)\n",
        "df_cleaned['sasdate'] = pd.to_datetime(df_cleaned['sasdate'], format='%m/%d/%Y')\n",
        "df_cleaned\n",
        "#selecting our variable \"INDPRO\"\n",
        "Y = df_cleaned['INDPRO']\n",
        "Y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiieEebXMDlh",
        "outputId": "6b41c923-c085-47dc-a29a-c5b9fee793fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       21.9665\n",
              "1       22.3966\n",
              "2       22.7193\n",
              "3       23.2032\n",
              "4       23.5528\n",
              "         ...   \n",
              "776    103.2096\n",
              "777    102.3722\n",
              "778    102.6710\n",
              "779    102.6715\n",
              "780    102.5739\n",
              "Name: INDPRO, Length: 781, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#codes implementation from assignment\n",
        "def lagged_matrix(Y, max_lag=7):\n",
        "    n = len(Y)\n",
        "    lagged_matrix = np.full((n, max_lag), np.nan)\n",
        "    # Fill each column with the appropriately lagged data\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        lagged_matrix[lag:, lag - 1] = Y[:-lag]\n",
        "    return lagged_matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "VcbRMl-bMGds"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unconditional_ar_mean_variance(c, phis, sigma2):\n",
        "## The length of phis is p\n",
        "   p = len(phis)\n",
        "   A = np.zeros((p, p))\n",
        "   A[0, :] = phis\n",
        "   A[1:, 0:(p-1)] = np.eye(p-1)\n",
        "# Check for stationarity\n",
        "   eigA = np.linalg.eig(A)\n",
        "   if all(np.abs(eigA.eigenvalues)<1):\n",
        "      stationary = True\n",
        "   else:\n",
        "      stationary = False\n",
        "# Create the vector b\n",
        "   b = np.zeros((p, 1))\n",
        "   b[0, 0] = c\n",
        "# Compute the mean using matrix algebra\n",
        "   I = np.eye(p)\n",
        "   mu = np.linalg.inv(I - A) @ b\n",
        "# Solve the discrete Lyapunov equation\n",
        "   Q = np.zeros((p, p))\n",
        "   Q[0, 0] = sigma2\n",
        "#Sigma = np.linalg.solve(I - np.kron(A, A), Q.flatten()).reshape(7, 7)\n",
        "   Sigma = scipy.linalg.solve_discrete_lyapunov(A, Q)\n",
        "   return mu.ravel(), Sigma, stationary\n",
        "## Conditional Likelihood\n",
        "def cond_loglikelihood_ar7(params, y):\n",
        "   c = params[0]\n",
        "   phi = params[1:8]\n",
        "   sigma2 = params[8]\n",
        "   mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)\n",
        "## We could check that at phis the process is stationary and return -Inf if it is not\n",
        "   if not(stationary):\n",
        "      return -np.inf\n",
        "   X = lagged_matrix(y, 7)\n",
        "   yf = y[7:]\n",
        "   Xf = X[7:,:]\n",
        "   loglik = np.sum(norm.logpdf(yf, loc=(c + Xf@phi), scale=np.sqrt(sigma2)))\n",
        "   return loglik"
      ],
      "metadata": {
        "id": "oogh87mAGiwH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Unconditional Likelihood\n",
        "def uncond_loglikelihood_ar7(params, y):\n",
        "## The unconditional loglikelihood\n",
        "## is the unconditional \"plus\" the density of the\n",
        "## first p (7 in our case) observations\n",
        "   cloglik = cond_loglikelihood_ar7(params, y)\n",
        "## Calculate initial\n",
        "# y_1, ..., y_7 ~ N(mu, sigma_y)\n",
        "   c = params[0]\n",
        "   phi = params[1:8]\n",
        "   sigma2 = params[8]\n",
        "   mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)\n",
        "   if not(stationary):\n",
        "      return -np.inf\n",
        "   mvn = multivariate_normal(mean=mu, cov=Sigma, allow_singular=True)\n",
        "   uloglik = cloglik + mvn.logpdf(y[0:7])\n",
        "   return uloglik\n",
        "# Using INDPRO as the target variable.\n",
        "## Computing OLS\n",
        "X = lagged_matrix(INDPRO, 7)\n",
        "yf = INDPRO[7:]\n",
        "Xf = np.hstack((np.ones((len(INDPRO)-7,1)), X[7:,:]))\n",
        "beta = np.linalg.solve(Xf.T@Xf, Xf.T@yf)\n",
        "sigma2_hat = np.mean((yf - Xf@beta)**2)\n",
        "params= np.hstack((beta, sigma2_hat))\n",
        "print(\"The parameters of the OLS model are\", params)\n",
        "# to maximize likelihood a function of the negative likelihood is defined to be minimized\n",
        "params = np.array([\n",
        "    0.0012, ## c\n",
        "    0.0291, 0.07, 0.059, 0.04, 0.04, 0.02, 0.06, ## phi\n",
        "    0.008 ## sigma2\n",
        "    ])\n",
        "def cobj(params, y):\n",
        "    return - cond_loglikelihood_ar7(params,y)\n",
        "#Same Procedure for unconditional likelihood\n",
        "params= np.hstack((beta, sigma2_hat))"
      ],
      "metadata": {
        "id": "ADYIx8WuHjg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Parameter estimation\n",
        "# Define y:\n",
        "y = Y\n",
        "\n",
        "# Ordinary Least Squares:\n",
        "X = lagged_matrix(y, 7)\n",
        "yf = y[7:]\n",
        "Xf = np.hstack((np.ones((len(yf),1)), X[7:,:]))\n",
        "\n",
        "# Estimate the parameters and the variance:\n",
        "beta = np.linalg.solve(Xf.T@Xf, Xf.T@yf)\n",
        "beta        # To see the estimates\n",
        "sigma2_hat = np.mean((yf - Xf@beta)**2)\n",
        "\n",
        "# They are concatenated into a single vector:\n",
        "params = np.hstack((beta, sigma2_hat))\n",
        "# Negative value of the conditional log-likelihood:\n",
        "def cobj(params, y):\n",
        "\n",
        "    # Compute the value of the objective function:\n",
        "    value = -cond_loglikelihood_ar7(params, y)\n",
        "\n",
        "    # Handle invalid values:\n",
        "    if np.isnan(value):\n",
        "        # If the value is invalid, return a large value to indicate an error:\n",
        "        return 1e12\n",
        "    else:\n",
        "        # Otherwise, return the computed value:\n",
        "        return value\n",
        "\n",
        "# Minimize the conditional log-likelihood using the L-BFGS-B algorithm:\n",
        "results1 = scipy.optimize.minimize(cobj, params, args = y, method='L-BFGS-B')\n",
        "results1\n",
        "\n",
        "# We can see that the values of result.x are equal to the OLS parameters\n",
        "\n",
        "## Not the conditional\n",
        "\n",
        "def uobj(params, y):\n",
        "    return - uncond_loglikelihood_ar7(params,y)\n",
        "\n",
        "bounds_constant = tuple((-np.inf, np.inf) for _ in range(1))\n",
        "bounds_phi = tuple((-1, 1) for _ in range(7))\n",
        "bounds_sigma = tuple((0,np.inf) for _ in range(1))\n",
        "bounds = bounds_constant + bounds_phi + bounds_sigma\n",
        "\n",
        "## L-BFGS-B support bounds\n",
        "results2 = scipy.optimize.minimize(uobj, results1.x, args = y, method='L-BFGS-B', bounds = bounds)\n",
        "results2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_TCgD29L4vl",
        "outputId": "71393436-e0d7-4684-dc80-8bfc60765aa1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
            "  df = fun(x) - f0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
              "  success: True\n",
              "   status: 0\n",
              "      fun: 32118.58642427295\n",
              "        x: [ 1.861e-01  1.000e+00 -3.541e-01  1.538e-01  6.122e-02\n",
              "            -3.235e-02  9.619e-02 -6.772e-02  1.318e+00]\n",
              "      nit: 3\n",
              "      jac: [-5.670e+03 -4.387e+05 -4.381e+05 -4.374e+05 -4.367e+05\n",
              "            -4.361e+05 -4.354e+05 -4.348e+05 -2.345e+04]\n",
              "     nfev: 50\n",
              "     njev: 5\n",
              " hess_inv: <9x9 LbfgsInvHessProduct with dtype=float64>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.forecasting!\n",
        "# Define the function for the AR(7) model:\n",
        "def forecast_ar7(params, y):\n",
        "    c = params[0]\n",
        "    phi = params[1:8]\n",
        "    sigma2 = params[8]\n",
        "    # Create the lagged matrix (h=8):\n",
        "    X_forecast = lagged_matrix(y, 7)[-8:, :]\n",
        "    # Compute the forecast:\n",
        "    forecast = c + np.dot(X_forecast, phi)\n",
        "    return forecast\n",
        "\n",
        "# the starting date:\n",
        "start_date = '2000-01-01'\n",
        "forecast_dates = pd.date_range(start=start_date, periods=8, freq='MS')\n",
        "\n",
        "# Forecast using the parameters from the conditional approach:\n",
        "forecast_conditional = forecast_ar7(results1.x, Y)\n",
        "\n",
        "# Forecast using the parameters from the unconditional approach:\n",
        "forecast_unconditional = forecast_ar7(results2.x, Y)\n",
        "\n",
        "# Create a Dataframe for the forecasts:\n",
        "forecast_df = pd.DataFrame({'Date': forecast_dates,\n",
        "                            'Conditional Forecast': forecast_conditional,\n",
        "                            'Unconditional Forecast': forecast_unconditional})\n",
        "\n",
        "# View:\n",
        "print(forecast_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP7NkGLYOHq8",
        "outputId": "24d54dba-ad3e-49f1-9fad-3d476a6449d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date  Conditional Forecast  Unconditional Forecast\n",
            "0 2000-01-01            102.717976               88.117999\n",
            "1 2000-02-01            102.314043               87.864974\n",
            "2 2000-03-01            103.551574               88.897732\n",
            "3 2000-04-01            103.012569               88.388536\n",
            "4 2000-05-01            103.296057               88.658018\n",
            "5 2000-06-01            102.217203               87.794609\n",
            "6 2000-07-01            102.836164               88.326577\n",
            "7 2000-08-01            102.742699               88.228601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "errors_conditional = []\n",
        "errors_unconditional = []\n",
        "# Calculate the error for each monthly forecast:\n",
        "for i in range(8):\n",
        "    error_conditional = mean_squared_error([Y[i]], [forecast_conditional[i]])\n",
        "    errors_conditional.append(error_conditional)\n",
        "\n",
        "    error_unconditional = mean_squared_error([Y[i]], [forecast_unconditional[i]])\n",
        "    errors_unconditional.append(error_unconditional)\n",
        "\n",
        "# Square root of the mean squared errors\n",
        "rmses_conditional = [np.sqrt(error) for error in errors_conditional]\n",
        "rmses_unconditional = [np.sqrt(error) for error in errors_unconditional]\n",
        "\n",
        "print(\"Conditional monthly forecast MSE):\", errors_conditional)\n",
        "print(\"Conditional monthly forecast RMSE:\", rmses_conditional)\n",
        "\n",
        "print(\"Unconditional monthly forecast MSE):\", errors_unconditional)\n",
        "print(\"Unconditional monthly forecast RMSE:\", rmses_unconditional)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQTPEwHuW7pi",
        "outputId": "db6ee6e8-54dc-4357-d18d-c2a71485fe9e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional monthly forecast MSE): [6520.8008919832355, 6386.797717312388, 6533.856543663836, 6369.535309977541, 6358.987024851885, 6183.856956252999, 6371.418250842376, 6481.441329996744]\n",
            "Conditional monthly forecast RMSE: [80.75147609785988, 79.91744313547818, 80.83227414630765, 79.80936856019812, 79.74325692403016, 78.63750349707828, 79.82116417869622, 80.50739922514417]\n",
            "Unconditional monthly forecast MSE): [4376.020838430186, 4286.1079801554215, 4379.584822773864, 4249.127979597197, 4238.689456593092, 4123.554501034424, 4265.602077390552, 4355.115734107759]\n",
            "Unconditional monthly forecast RMSE: [66.15149913970345, 65.46837389270809, 66.17843170379504, 65.18533561773842, 65.10521835147388, 64.21490871312069, 65.3115769017297, 65.99330067596073]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The presence of positive values in both conditional and unconditional forecasts indicates an expected uptrend in industrial production, while negative values imply a projected decline. Fluctuations between positive and negative values suggest inherent uncertainty or volatility in the industrial production outlook. Considering the pivotal role of industrial production in driving economic growth, these forecasts suggest potential periods of both expansion and contraction in the industrial sector over the eight-month period. Various factors including interest rate changes, governmental policies impacting the industrial sector, and shifts in global demand for manufactured goods could contribute to fluctuations in industrial production.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4zxfabnpXNsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}